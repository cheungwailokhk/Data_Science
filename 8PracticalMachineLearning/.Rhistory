preProc <- preProcess(trainingIL[,!(colnames(trainingIL) %in% c("diagnosis"))]
,method="pca",thresh=0.8)
# Apply PCA to the training data
trainPC <- predict(preProc,trainingIL[,!(colnames(trainingIL) %in% c("diagnosis"))])
# fit a model by glm
modelFit_PCA<- train(x = trainPC, y = trainingIL$diagnosis,method="glm")
modelFit_PCA # training model with PCA accuracy
#modelFit <- train(diagnosis ~ .,method="glm",data=trainPC)
# Preprocessing testing data by the same PCA model
testPC <- predict(preProc,testingIL[,!(colnames(testingIL) %in% c("diagnosis"))])
# Apply model to testing data
predictions <- predict(modelFit_PCA,newdata=testPC)
predictions
confusionMatrix(testing$diagnosis,predictions)
# PCA
modelPCA <- train(diagnosis ~., data = trainingIL, method = "glm", preProcess = "pca",trControl=trainControl(preProcOptions=list(thresh=0.8)))
matrix_modelPCA <- confusionMatrix(testingIL$diagnosis, predict(modelPCA, testingIL))
matrix_modelPCA$overall[1]
# non-PCA
model <- train(diagnosis ~ ., data = trainingIL, method = "glm")
predict_model <- predict(model, newdata= testingIL)
matrix_model <- confusionMatrix(predict_model, testingIL$diagnosis)
matrix_model$overall[1]
# PCA
modelFit_PCA2 <- train(diagnosis ~., data = trainingIL, method = "glm", preProcess = "pca",trControl=trainControl(preProcOptions=list(thresh=0.8)))
confusionMatrix(testingIL$diagnosis, predict(modelFit_PCA2, testingIL))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
# PCA
modelFit_PCA <- train(diagnosis ~., data = trainingIL,
method = "glm", preProcess = "pca",
trControl=trainControl(preProcOptions=list(thresh=0.8)))
confusionMatrix(testingIL$diagnosis, predict(modelFit_PCA, testingIL))
# PCA
modelFit_PCA <- train(diagnosis ~., data = trainingIL,
method = "glm", preProcess = "pca",
trControl=trainControl(preProcOptions=list(thresh=0.8)))
confusionMatrix(testingIL$diagnosis, predict(modelFit_PCA, testingIL))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# 2. Preprocessing training data by PCA
# filter the predicting column, and find out PCA
preProc <- preProcess(trainingIL[,!(colnames(trainingIL) %in% c("diagnosis"))]
,method="pca",thresh=0.8)
# Apply PCA to the training data
trainPC <- predict(preProc,trainingIL[,!(colnames(trainingIL) %in% c("diagnosis"))])
# fit a model by glm
modelFit_PCA<- train(x = trainPC, y = trainingIL$diagnosis,method="glm")
modelFit_PCA # training model with PCA accuracy
#modelFit <- train(diagnosis ~ .,method="glm",data=trainPC)
# 2. Preprocessing training data by PCA
# filter the predicting column, and find out PCA
preProc <- preProcess(trainingIL[,!(colnames(trainingIL) %in% c("diagnosis"))]
,method="pca",thresh=0.8)
# Apply PCA to the training data
trainPC <- predict(preProc,trainingIL[,!(colnames(trainingIL) %in% c("diagnosis"))])
# fit a model by glm
modelFit_PCA<- train(x = trainPC, y = trainingIL$diagnosis,method="glm")
modelFit_PCA # training model with PCA accuracy
#modelFit <- train(diagnosis ~ .,method="glm",data=trainPC)
# Preprocessing testing data by the same PCA model
testPC <- predict(preProc,testingIL[,!(colnames(testingIL) %in% c("diagnosis"))])
# Apply model to testing data
predictions <- predict(modelFit_PCA,newdata=testPC)
confusionMatrix(testing$diagnosis,predictions)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# 2. Preprocessing training data by PCA
# filter the predicting column, and find out PCA
preProc <- preProcess(trainingIL[,!(colnames(trainingIL) %in% c("diagnosis"))]
,method="pca",thresh=0.8)
# Apply PCA to the training data
trainPC <- predict(preProc,trainingIL[,!(colnames(trainingIL) %in% c("diagnosis"))])
# fit a model by glm
modelFit_PCA<- train(x = trainPC, y = trainingIL$diagnosis,method="glm")
modelFit_PCA # training model with PCA accuracy
#modelFit <- train(diagnosis ~ .,method="glm",data=trainPC)
# Preprocessing testing data by the same PCA model
testPC <- predict(preProc,testingIL[,!(colnames(testingIL) %in% c("diagnosis"))])
# Apply model to testing data
predictions <- predict(modelFit_PCA,newdata=testPC)
confusionMatrix(testing$diagnosis,predictions)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
segmentationOriginal
str(segmentationOriginal)
training <- segmentationOriginal[Case=1]
head(segmentationOriginal$Case)
training <- segmentationOriginal[segmentationOriginal$Case="Test"]
testing <- segmentationOriginal[segmentationOriginal$Case="Train"]
training <- segmentationOriginal[segmentationOriginal$Case=="Test",]
testing <- segmentationOriginal[segmentationOriginal$Case="Train",]
training <- segmentationOriginal[segmentationOriginal$Case=="Test",]
testing <- segmentationOriginal[segmentationOriginal$Case=="Train",]
set.seed(125)
str(segmentationOriginal)
training <- segmentationOriginal[segmentationOriginal$Case=="Test",]
testing <- segmentationOriginal[segmentationOriginal$Case=="Train",]
set.seed(125)
modFit <- train(Class ~ .,method="rpart",data=training)
modFit
TotalIntench2 <- c(23000)
FiberWidthCh1 <- c(10)
PerimStatusCh1 <- c(2)
df = dataframe(TotalIntench2,FiberWidthCh1,PerimStatusCh1)
TotalIntench2 <- c(23000)
FiberWidthCh1 <- c(10)
PerimStatusCh1 <- c(2)
df = as.dataframe(TotalIntench2,FiberWidthCh1,PerimStatusCh1)
TotalIntench2 <- c(23000)
FiberWidthCh1 <- c(10)
PerimStatusCh1 <- c(2)
df = data.frame(TotalIntench2,FiberWidthCh1,PerimStatusCh1)
predict(modFit, newdata=df)
names(testing)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE)
training <- segmentationOriginal[inTrain,] # split dataset
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Class ~ .,method="rpart",data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
modFit <- train(Area ~ .,method="rpart",data=training)
inTrain <- createDataPartition(y = olive$Case, p = 0.6, list = FALSE)
training <- olive[inTrain,] # split dataset
testing <- olive[-inTrain,]
modFit <- train(Area ~ .,method="rpart",data=training)
head(training)
modFit <- train(Area ~ .,method="rpart",data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = newdata
)
library(rattle)
fancyRpartPlot(modFit$finalModel)
modFit <- train(Area ~ .,method="rpart",data=training)
inTrain <- createDataPartition(y = olive$Case, p = 0.6, list = FALSE)
training <- olive[inTrain,] # split dataset
modFit <- train(Area ~ .,method="rpart",data=training)
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
inTrain <- createDataPartition(y = olive$Case, p = 0.6, list = FALSE)
head(olive)
modFit <- train(Area ~ .,method="rpart",data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = newdata)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
inTrain <- createDataPartition(y = olive$Case, p = 0.6, list = FALSE)
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
inTrain <- createDataPartition(y = olive$Case, p = 0.6, list = FALSE)
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
modFit <- train(Area ~ .,method="rpart",data=olive)
library(rattle)
fancyRpartPlot(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = newdata)
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
modFit <- train(Area ~ .,method="rpart",data=olive)
library(rattle)
fancyRpartPlot(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = newdata)
library(caret)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages(ElemStatLearn)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(caret)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage <- subset(Wage,select=-c(logwage))
# Create a building data set and validation set
inBuild <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
validation <- Wage[-inBuild,]; buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y=buildData$wage,
p=0.7, list=FALSE)
training <- buildData[inTrain,]; testing <- buildData[-inTrain,]
install.packages("ISLR")
library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage <- subset(Wage,select=-c(logwage))
# Create a building data set and validation set
inBuild <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
validation <- Wage[-inBuild,]; buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y=buildData$wage,
p=0.7, list=FALSE)
training <- buildData[inTrain,]; testing <- buildData[-inTrain,]
mod1 <- train(wage ~.,method="glm",data=training)
mod2 <- train(wage ~.,method="rf",
data=training,
trControl = trainControl(method="cv"),number=3)
pred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)
qplot(pred1,pred2,colour=wage,data=testing)
mod1 <- train(wage ~.,method="glm",data=training)
mod2 <- train(wage ~.,method="rf",
data=training,
trControl = trainControl(method="cv"),number=3))
pred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)
qplot(pred1,pred2,colour=wage,data=testing)
pred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)
mod2 <- train(wage ~.,method="rf",
data=training,
trControl = trainControl(method="cv"),number=3))
mod2 <- train(wage ~.,method="rf",
data=training,
trControl = trainControl(method="cv"),number=3)
mod1 <- train(wage ~.,method="glm",data=training)
mod2 <- train(wage ~.,method="rf",
data=training,
trControl = trainControl(method="cv"),number=3)
pred1 <- predict(mod1,testing); pred2 <- predict(mod2,testing)
qplot(pred1,pred2,colour=wage,data=testing)
predDF <- data.frame(pred1,pred2,wage=testing$wage)
head(predDF)
View(predDF)
View(training)
combModFit <- train(wage ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
combPred
combModFit
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
from.dat <- as.Date("01/01/20", format="%m/%d/%y")
to.dat <- as.Date("12/03/21", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
getSymbols("ADBE", src="google", from = from.dat, to = to.dat)
from.dat <- as.Date("01/01/20", format="%m/%d/%y")
to.dat <- as.Date("12/03/21", format="%m/%d/%y")
getSymbols("ADBE", src="yahoo", from = from.dat, to = to.dat)
from.dat <- as.Date("01/01/21", format="%m/%d/%y")
to.dat <- as.Date("12/03/21", format="%m/%d/%y")
getSymbols("ADBE", src="yahoo", from = from.dat, to = to.dat)
from.dat <- as.Date("01/01/21", format="%m/%d/%y")
to.dat <- as.Date("12/03/21", format="%m/%d/%y")
getSymbols("AMZN", src="yahoo", from = from.dat, to = to.dat)
from.dat <- as.Date("12/01/21", format="%m/%d/%y")
to.dat <- as.Date("01/31/21", format="%m/%d/%y")
getSymbols("AMZN", src="yahoo", from = from.dat, to = to.dat)
getSymbols("AAPL", from="1990-01-01", src="yahoo")
View(AAPL)
getSymbols("PLTR", from="2020-12-31", src="yahoo")
View(PLTR)
getSymbols("PLTR", from="2020-12-31", to = "2021-01-31", src="yahoo")
View(PLTR)
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
getSymbols("GOOG", src="yahoo", from = from.dat, to = to.dat)
View(GOOG)
View(GOOG)
mGoog <- to.monthly(GOOG)
View(mGoog)
View(GOOG)
View(mGoog)
googOpen <- Op(mGoog)
View(mGoog)
View(googOpen)
View(mGoog)
View(googOpen)
?ts
View(mGoog)
View(googOpen)
?Op
View(googOpen)
View(mGoog)
?ts
ts1Train <- window(ts1,start=1,end=5)
ts1Test <- window(ts1,start=5,end=(7-0.01))
ts1Train
mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
ts1 <- ts(googOpen,frequency=12)
ts1Train <- window(ts1,start=1,end=5)
ts1Test <- window(ts1,start=5,end=(7-0.01))
ts1Train
ts1Train <- window(ts1,start=1,end=5)
ts1Train
ts1Test
ts1
ts1Train
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages("ElemStatLearn")
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
rfmodel <- train(diagnosis~., data=training, method="rf")
gbmmodel <- train(diagnosis~., data=training, method="gbm")
idamodel <- train(diagnosis~., data=training, method="ida")
idamodel <- train(diagnosis~., data=training, method="lda")
prf <- predict(rfmodel, testing)
pgbm<- predict(gbmmodel, testing)
pida<- predict(idamodel, testing)
confusionMatrix(testing$y, prf)
confusionMatrix(testing$y, pgbm)
confusionMatrix(testing$y, pida)
prf <- predict(rfmodel, testing)
confusionMatrix(testing$diagnosis, prf)
prf <- predict(rfmodel, testing)
pgbm<- predict(gbmmodel, testing)
pida<- predict(idamodel, testing)
confusionMatrix(testing$diagnosis, prf)
confusionMatrix(testing$diagnosis, pgbm)
confusionMatrix(testing$diagnosis, pida)
predDF <- data.frame(prf,pgbm,pida, diagnosis=testing$diagnosis)
combModFit <- train(diagnosis ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
combPred
predDF <- data.frame(prf,pgbm,pida, diagnosis=training$diagnosis)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
combModFit
confusionMatrix(testing$diagnosis, prf)
confusionMatrix(testing$diagnosis, pgbm)
confusionMatrix(testing$diagnosis, pida)
# Fit a model that combines predictors on training set
predDF <- data.frame(prf,pgbm,pida, diagnosis=testing$diagnosis)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
getwd()
setwd("/Users/l/Documents/Google_Drive/Workplace-JP/Workspace/R/datasciencecoursera/8PracticalMachineLearning")
training = read.csv("./training.csv")
testing = read.csv("./testing.csv")
getwd()
training = read.csv("./PA_data/training.csv")
testing = read.csv("./PA_data/testing.csv")
library(caret)
str(training)
names(training)
sort(names(training))
training$classe
str(training$classe)
library(caret); library(dplyr)
distinct(training$classe)
list(training$classe)
distinct(list(training$classe))
?distinct
distinct(training         )
distinct(subset(training, c('classe')))
distinct(subset(training, select=c('classe')))
trainingUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-tra.csv"
testingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-test.csv"
training_dest <- "./data/pml-training.csv"
testing_dest <- "./data/pml-testing.csv"
if (!file.exists("./PA_data")) {
dir.create("./PA_data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
training = read.csv("./PA_data/training.csv")
testing = read.csv("./PA_data/testing.csv")
if (!file.exists(trainFile)) {
download.file(training_url, destfile=training_dest, method="curl")
}
if (!file.exists(trainFile)) {
download.file(testing_url, destfile=testing_dest, method="curl")
}
if (!file.exists(training_dest)) {
download.file(training_url, destfile=training_dest, method="curl")
}
if (!file.exists(testing_dest)) {
download.file(testing_url, destfile=testing_dest, method="curl")
}
training_url <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-tra.csv"
testing_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-test.csv"
training_dest <- "./data/pml-training.csv"
testing_dest <- "./data/pml-testing.csv"
if (!file.exists("./PA_data")) {
dir.create("./PA_data")
}
if (!file.exists(training_dest)) {
download.file(training_url, destfile=training_dest, method="curl")
}
if (!file.exists(testing_dest)) {
download.file(testing_url, destfile=testing_dest, method="curl")
}
training = read.csv("./PA_data/training.csv")
testing = read.csv("./PA_data/testing.csv")
training = read.csv(training_dest)
testing = read.csv(testing_dest)
training = read.csv(training_dest)
download.file(training_url, destfile=training_dest, method="curl")
training = read.csv(training_url)
training_url <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testing_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training = read.csv(training_url)
testing = read.csv(testing_dest)
testing = read.csv(testing_url)
str(training)
any(is.na(training) | is.infinite(training))
apply(df, 2, function(x) any(is.na(training)))
head(str(training))
head(str(training), 10)
is.na(training)
any(is.na(training))
All(is.na(training))
all(is.na(training))
# Check any na in training dataset
any(is.na(training))
# Check any na in testing dataset
any(is.na(testing))
rm(training_url, testing_url)
training <- training[complete.cases(training),]
testing <- testing[complete.cases(testing),]
View(training)
View(testing)
training_url <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testing_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training = read.csv(training_url)
testing = read.csv(testing_url)
rm(training_url, testing_url)
View(testing)
View(training)
View(testing)
View(training)
str(training)
training1 <- training[,colSums(is.na(training))<nrow(training)]
```
View(training1)
training2 <- training[complete.cases(training),]
dim(training)
training1 <- training[,colSums(is.na(training))< (nrow(training))*0.1]
training1 <- training[,colSums(is.na(training))< (nrow(training))*0.2]
training1 <- training[,colSums(is.na(training))< (nrow(training))*0.1]
training1 <- training[,colSums(is.na(training))< (nrow(training))*0.1]
training1 <- training[,colSums(is.na(training))< (nrow(training))*0.3]
training1 <- training[,colSums(is.na(training))< (nrow(training))*0.9]
training1 <- training[,colSums(is.na(training))< ((nrow(training))*0.9)]
training1 <- training[,colSums(is.na(training))< ((nrow(training))*0.1)]
View(training1)
((nrow(training))*0.1)
training[,colSums(is.na(training))< ((nrow(training))*0.1)]
View(training2)
View(training)
View(training)
